{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d6406d-80b5-46c3-bda1-dd190c675d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U transformers huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3cd4b-f6a3-4345-993d-47557f42c553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the notebook_login function\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# Call the notebook_login function to log in\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06f29857-2d7a-4702-8e49-f89619ab120c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884a42372b3c405aa9eef229bc1d9b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4186d9dfc34315bb36a8f58b13856c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrrr, me hearty! I be Captain Chatbot, the scurviest pirate to ever sail the Seven Seas! Me and me trusty ship, the \"Digital Davy Jones\", be here to bring ye the treasure of knowledge and swashbucklin' fun! Yer welcome to join me crew and set sail fer a life o' adventure and booty!\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8233493-b2ea-401d-bf82-a0128ed57810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a step-by-step guide to create a Python script to validate JSON schema using Pydantic:\n",
      "\n",
      "**Step 1: Install Pydantic**\n",
      "\n",
      "You can install Pydantic using pip:\n",
      "```\n",
      "pip install pydantic\n",
      "```\n",
      "**Step 2: Define the JSON Schema**\n",
      "\n",
      "Create a new file (e.g., `schema.py`) and define the JSON schema using Pydantic's `BaseModel`:\n",
      "```python\n",
      "from pydantic import BaseModel\n",
      "\n",
      "class MyModel(BaseModel):\n",
      "    name: str\n",
      "    age: int\n",
      "    email: str\n",
      "```\n",
      "In this example, we define a `MyModel` class with three fields: `name`, `age`, and `email`. The types of these fields are specified using Pydantic's type hints (e.g., `str` for `name` and `int` for `age`).\n",
      "\n",
      "**Step 3: Create a Validator**\n",
      "\n",
      "Create a new file (e.g., `validator.py`) and import the `MyModel` class:\n",
      "```python\n",
      "from schema import MyModel\n",
      "\n",
      "def validate_json(json_data):\n",
      "    try:\n",
      "        model = MyModel.parse_raw(json_data)\n",
      "        return True\n",
      "    except ValidationError as e:\n",
      "        return str(e)\n",
      "```\n",
      "In this example, we define a `validate_json` function that takes a JSON string as input. We use the `parse_raw` method to parse the JSON data into an instance of `MyModel`. If the parsing is successful, we return `True`. If a `ValidationError` occurs, we catch the exception and return the error message as a string.\n",
      "\n",
      "**Step 4: Test the Validator**\n",
      "\n",
      "Create a test file (e.g., `test_validator.py`) and test the `validate_json` function:\n",
      "```python\n",
      "import json\n",
      "from validator import validate_json\n",
      "\n",
      "# Valid JSON data\n",
      "valid_json = '{\"name\": \"John\", \"age\": 30, \"email\": \"john@example.com\"}'\n",
      "assert validate_json(valid_json) == True\n",
      "\n",
      "# Invalid JSON data (missing field)\n",
      "invalid_json = '{\"name\": \"John\", \"age\": 30}'\n",
      "assert validate_json(invalid_json) == \"1 validation error - mt\"\n",
      "\n",
      "# Invalid JSON data (invalid type)\n",
      "invalid_json = '{\"name\": \"John\", \"age\": \"thirty\", \"email\": \"john@example.com\"}'\n",
      "assert validate_json(invalid_json) == \"1 validation error - mt\"\n",
      "```\n",
      "In this example, we test the `validate_json` function with three different JSON strings:\n",
      "\n",
      "1. A valid JSON string that passes the validation.\n",
      "2. An invalid JSON string that is missing the `email` field.\n",
      "3. An invalid JSON string that has an invalid type for the `age` field.\n",
      "\n",
      "**Step 5: Run the Script**\n",
      "\n",
      "You can run the script using Python:\n",
      "```\n",
      "python validator.py\n",
      "```\n",
      "This will execute the `validate_json` function and print the results to the console.\n",
      "\n",
      "That's it! You now have a Python script that validates JSON schema using Pydantic.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a coding assistant, answer user queries as requested\"},\n",
    "    {\"role\": \"user\", \"content\": \"Help me create a python script to validate json schema in the input using pydantic. Guide me through the process.\"},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=4096,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fca111d-1338-4bcd-abcb-03df9e2765ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to help you create a simple REST API in Python using Flask. Here's a step-by-step guide to create a basic CRUD (Create, Read, Update, Delete) API for a 'products' resource:\n",
      "\n",
      "**Step 1: Install Flask**\n",
      "\n",
      "If you haven't installed Flask yet, you can do so by running the following command in your terminal:\n",
      "```\n",
      "pip install flask\n",
      "```\n",
      "**Step 2: Create a new Flask app**\n",
      "\n",
      "Create a new file called `app.py` and add the following code:\n",
      "```python\n",
      "from flask import Flask, jsonify, request\n",
      "\n",
      "app = Flask(__name__)\n",
      "\n",
      "# Sample products data\n",
      "products = [\n",
      "    {\"id\": 1, \"name\": \"Product 1\", \"price\": 10.99},\n",
      "    {\"id\": 2, \"name\": \"Product 2\", \"price\": 9.99},\n",
      "    {\"id\": 3, \"name\": \"Product 3\", \"price\": 12.99}\n",
      "]\n",
      "```\n",
      "This code creates a new Flask app and defines a sample list of products.\n",
      "\n",
      "**Step 3: Define API endpoints**\n",
      "\n",
      "Add the following code to define the API endpoints:\n",
      "```python\n",
      "@app.route('/products', methods=['GET'])\n",
      "def get_products():\n",
      "    return jsonify(products)\n",
      "\n",
      "@app.route('/products/<int:product_id>', methods=['GET'])\n",
      "def get_product(product_id):\n",
      "    for product in products:\n",
      "        if product['id'] == product_id:\n",
      "            return jsonify(product)\n",
      "    return jsonify({\"error\": \"Product not found\"}), 404\n",
      "\n",
      "@app.route('/products', methods=['POST'])\n",
      "def create_product():\n",
      "    new_product = {\n",
      "        \"id\": len(products) + 1,\n",
      "        \"name\": request.json['name'],\n",
      "        \"price\": request.json['price']\n",
      "    }\n",
      "    products.append(new_product)\n",
      "    return jsonify(new_product), 201\n",
      "\n",
      "@app.route('/products/<int:product_id>', methods=['PUT'])\n",
      "def update_product(product_id):\n",
      "    for product in products:\n",
      "        if product['id'] == product_id:\n",
      "            product['name'] = request.json.get('name', product['name'])\n",
      "            product['price'] = request.json.get('price', product['price'])\n",
      "            return jsonify(product)\n",
      "    return jsonify({\"error\": \"Product not found\"}), 404\n",
      "\n",
      "@app.route('/products/<int:product_id>', methods=['DELETE'])\n",
      "def delete_product(product_id):\n",
      "    for product in products:\n",
      "        if product['id'] == product_id:\n",
      "            products.remove(product)\n",
      "            return jsonify({\"message\": \"Product deleted\"})\n",
      "    return jsonify({\"error\": \"Product not found\"}), 404\n",
      "```\n",
      "This code defines the following API endpoints:\n",
      "\n",
      "* `GET /products`: Returns a list of all products\n",
      "* `GET /products/<int:product_id>`: Returns a single product by ID\n",
      "* `POST /products`: Creates a new product\n",
      "* `PUT /products/<int:product_id>`: Updates a single product by ID\n",
      "* `DELETE /products/<int:product_id>`: Deletes a single product by ID\n",
      "\n",
      "**Step 4: Run the app**\n",
      "\n",
      "Run the app by executing the following command in your terminal:\n",
      "```\n",
      "python app.py\n",
      "```\n",
      "This will start the Flask development server, and you can test the API endpoints using a tool like `curl` or a web browser.\n",
      "\n",
      "**Step 5: Test the API**\n",
      "\n",
      "Use the following commands to test the API endpoints:\n",
      "\n",
      "* `curl http://localhost:5000/products`: Returns a list of all products\n",
      "* `curl http://localhost:5000/products/1`: Returns a single product by ID\n",
      "* `curl -X POST -H \"Content-Type: application/json\" -d '{\"name\": \"New Product\", \"price\": 15.99}' http://localhost:5000/products`: Creates a new product\n",
      "* `curl -X PUT -H \"Content-Type: application/json\" -d '{\"name\": \"Updated Product\", \"price\": 16.99}' http://localhost:5000/products/1`: Updates a single product by ID\n",
      "* `curl -X DELETE http://localhost:5000/products/1`: Deletes a single product by ID\n",
      "\n",
      "That's it! You now have a basic CRUD API for a 'products' resource using Flask.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a coding assistant, answer user queries as requested\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you guide me through creating a simple REST API in Python using Flask? I need the API to handle basic CRUD operations for a 'products' resource.\"},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=4096,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f9f7ff0-6ebd-4223-8c15-783db52f1b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a step-by-step guide to setting up a continuous integration pipeline for a Python project using GitHub Actions:\n",
      "\n",
      "**Step 1: Create a new GitHub Actions workflow file**\n",
      "\n",
      "In your repository, create a new file named `.github/workflows/main.yml`. This file will contain the workflow definition.\n",
      "\n",
      "**Step 2: Define the workflow**\n",
      "\n",
      "In the `main.yml` file, add the following YAML code:\n",
      "```yaml\n",
      "name: CI\n",
      "\n",
      "on:\n",
      "  push:\n",
      "    branches:\n",
      "      - main\n",
      "  pull_request:\n",
      "    branches:\n",
      "      - main\n",
      "\n",
      "jobs:\n",
      "  build-and-deploy:\n",
      "    runs-on: ubuntu-latest\n",
      "    steps:\n",
      "      - name: Checkout code\n",
      "        uses: actions/checkout@v2\n",
      "\n",
      "      - name: Set up Python\n",
      "        uses: actions/setup-python@v2\n",
      "        with:\n",
      "          python-version: '3.9'\n",
      "\n",
      "      - name: Install dependencies\n",
      "        run: |\n",
      "          pip install -r requirements.txt\n",
      "\n",
      "      - name: Run tests\n",
      "        run: |\n",
      "          python -m unittest discover tests/\n",
      "\n",
      "      - name: Deploy\n",
      "        uses: actions/deploy@v1\n",
      "        with:\n",
      "          provider: heroku\n",
      "          api-key: ${{ secrets.HEROKU_API_KEY }}\n",
      "          app-name: your-app-name\n",
      "```\n",
      "Let's break down the workflow:\n",
      "\n",
      "* `name`: The name of the workflow.\n",
      "* `on`: The events that trigger the workflow (in this case, pushes to the `main` branch and pull requests to the `main` branch).\n",
      "* `jobs`: The job that runs the workflow.\n",
      "* `runs-on`: The environment where the job runs (in this case, an `ubuntu-latest` environment).\n",
      "* `steps`: The individual steps that make up the job.\n",
      "* `Checkout code`: Checks out the code in the repository.\n",
      "* `Set up Python`: Sets up a Python environment with version 3.9.\n",
      "* `Install dependencies`: Installs the dependencies listed in `requirements.txt` using pip.\n",
      "* `Run tests`: Runs the tests using the `unittest` module.\n",
      "* `Deploy`: Deploys the application to Heroku using the `actions/deploy` action.\n",
      "\n",
      "**Step 3: Create a `requirements.txt` file**\n",
      "\n",
      "In the root of your repository, create a new file named `requirements.txt`. This file should list the dependencies required by your project.\n",
      "\n",
      "For example:\n",
      "```txt\n",
      "numpy==1.20.0\n",
      "pandas==1.3.5\n",
      "```\n",
      "**Step 4: Create a `tests` directory**\n",
      "\n",
      "Create a new directory named `tests` in the root of your repository. This directory will contain your test files.\n",
      "\n",
      "**Step 5: Write your tests**\n",
      "\n",
      "Write your tests using the `unittest` module. For example:\n",
      "```python\n",
      "import unittest\n",
      "from your_module import your_function\n",
      "\n",
      "class TestYourFunction(unittest.TestCase):\n",
      "    def test_your_function(self):\n",
      "        result = your_function()\n",
      "        self.assertEqual(result, expected_result)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    unittest.main()\n",
      "```\n",
      "**Step 6: Store your Heroku API key as a secret**\n",
      "\n",
      "In your repository settings, go to the \"Actions\" tab and click on \"Secrets\". Add a new secret named `HEROKU_API_KEY` with your Heroku API key.\n",
      "\n",
      "**Step 7: Trigger the workflow**\n",
      "\n",
      "Push changes to your repository or create a pull request to trigger the workflow.\n",
      "\n",
      "That's it! Your continuous integration pipeline should now be set up and running. The workflow will install dependencies, run tests, and deploy your application to Heroku whenever you push changes to your repository or create a pull request.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a coding assistant, answer user queries as requested\"},\n",
    "    {\"role\": \"user\", \"content\": \"Guide me through setting up a continuous integration pipeline for a Python project using GitHub Actions. Include steps to install dependencies, run tests, and deploy.\"},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=4096,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e9310d0-6cc9-4003-aaf7-53f2b4c79bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beautiful Soup is a powerful Python library used for parsing HTML and XML documents. It creates a parse tree from page source code that can be used to extract data in a hierarchical and more readable manner.\n",
      "\n",
      "Here's a step-by-step guide on how to use Beautiful Soup for web scraping:\n",
      "\n",
      "**Step 1: Install Beautiful Soup**\n",
      "\n",
      "You can install Beautiful Soup using pip:\n",
      "\n",
      "```\n",
      "pip install beautifulsoup4\n",
      "```\n",
      "\n",
      "**Step 2: Send a Request to the Website**\n",
      "\n",
      "You can use the `requests` library to send a GET request to the website:\n",
      "\n",
      "```\n",
      "import requests\n",
      "\n",
      "url = \"https://www.example.com\"\n",
      "response = requests.get(url)\n",
      "```\n",
      "\n",
      "**Step 3: Parse the HTML Content**\n",
      "\n",
      "Use Beautiful Soup to parse the HTML content:\n",
      "\n",
      "```\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "soup = BeautifulSoup(response.content, 'html.parser')\n",
      "```\n",
      "\n",
      "**Step 4: Extract the Data**\n",
      "\n",
      "Use Beautiful Soup's methods to extract the data you need. For example, you can use the `find()` method to find a specific tag:\n",
      "\n",
      "```\n",
      "title = soup.find('title').text\n",
      "print(title)\n",
      "```\n",
      "\n",
      "**Handling Pagination**\n",
      "\n",
      "Pagination is a common issue in web scraping. Here are a few ways to handle it:\n",
      "\n",
      "1. **Check if there's a next page link**: You can use Beautiful Soup to find the next page link and then send a request to that link.\n",
      "\n",
      "```\n",
      "next_page_link = soup.find('a', {'class': 'next-page'})\n",
      "if next_page_link:\n",
      "    next_page_url = next_page_link.get('href')\n",
      "    # Send a request to the next page\n",
      "    next_page_response = requests.get(next_page_url)\n",
      "    next_page_soup = BeautifulSoup(next_page_response.content, 'html.parser')\n",
      "    # Extract the data from the next page\n",
      "    #...\n",
      "```\n",
      "\n",
      "2. **Use a loop to scrape multiple pages**: You can use a loop to scrape multiple pages. For example, you can scrape the first 10 pages:\n",
      "\n",
      "```\n",
      "for i in range(1, 11):\n",
      "    page_url = f\"https://www.example.com/page/{i}\"\n",
      "    page_response = requests.get(page_url)\n",
      "    page_soup = BeautifulSoup(page_response.content, 'html.parser')\n",
      "    # Extract the data from the page\n",
      "    #...\n",
      "```\n",
      "\n",
      "3. **Use a recursive function to scrape multiple pages**: You can use a recursive function to scrape multiple pages. For example, you can scrape all pages until there's no next page link:\n",
      "\n",
      "```\n",
      "def scrape_pages(soup):\n",
      "    next_page_link = soup.find('a', {'class': 'next-page'})\n",
      "    if next_page_link:\n",
      "        next_page_url = next_page_link.get('href')\n",
      "        next_page_response = requests.get(next_page_url)\n",
      "        next_page_soup = BeautifulSoup(next_page_response.content, 'html.parser')\n",
      "        # Extract the data from the page\n",
      "        #...\n",
      "        scrape_pages(next_page_soup)\n",
      "    else:\n",
      "        # No next page link, stop scraping\n",
      "        pass\n",
      "\n",
      "scrape_pages(soup)\n",
      "```\n",
      "\n",
      "Remember to always check the website's terms of use and robots.txt file before scraping. Some websites may have restrictions on web scraping.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a coding assistant, answer user queries as requested\"},\n",
    "    {\"role\": \"user\", \"content\": \"I'm interested in web scraping with Python. Can you explain how to use Beautiful Soup to scrape data from HTML pages and handle common issues like pagination?\"},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=4096,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a0212dc-b5ad-46ed-9fc4-06a6bab7a562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The asyncio library in Python is used for writing single-threaded concurrent code using coroutines, multiplexing I/O access over sockets and other resources, and implementing network clients and servers.\n",
      "\n",
      "Here's a simple example of making asynchronous HTTP requests using the `aiohttp` library, which is a Python library for asynchronous I/O, built on top of the asyncio library.\n",
      "\n",
      "First, you need to install the `aiohttp` library. You can do this by running the following command in your terminal:\n",
      "\n",
      "```\n",
      "pip install aiohttp\n",
      "```\n",
      "\n",
      "Now, let's create a simple script that makes asynchronous HTTP requests:\n",
      "\n",
      "```python\n",
      "import aiohttp\n",
      "import asyncio\n",
      "\n",
      "async def fetch_page(session, url):\n",
      "    async with session.get(url) as response:\n",
      "        return await response.text()\n",
      "\n",
      "async def main():\n",
      "    urls = ['http://example.com/page1', 'http://example.com/page2', 'http://example.com/page3']\n",
      "    async with aiohttp.ClientSession() as session:\n",
      "        tasks = []\n",
      "        for url in urls:\n",
      "            task = asyncio.create_task(fetch_page(session, url))\n",
      "            tasks.append(task)\n",
      "        pages = await asyncio.gather(*tasks)\n",
      "        for page in pages:\n",
      "            print(page)\n",
      "\n",
      "asyncio.run(main())\n",
      "```\n",
      "\n",
      "In this script, we define two functions: `fetch_page` and `main`. The `fetch_page` function makes an asynchronous GET request to a given URL and returns the response text. The `main` function creates a list of URLs, creates a ClientSession, and then creates a task for each URL to fetch the page. The `asyncio.gather` function is used to wait for all tasks to complete and return their results.\n",
      "\n",
      "The `asyncio.run(main())` line is used to run the `main` function as an asynchronous task.\n",
      "\n",
      "When you run this script, it will make asynchronous HTTP requests to the given URLs and print the response text for each page.\n",
      "\n",
      "This is a very basic example of using the `aiohttp` library for making asynchronous HTTP requests. The `aiohttp` library provides many more features and options for making HTTP requests, such as handling cookies, headers, and more.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a coding assistant, answer user queries as requested\"},\n",
    "    {\"role\": \"user\", \"content\": \"Help me understand how to use the asyncio library in Python for asynchronous programming. Provide a simple example of making asynchronous HTTP requests.\"},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=4096,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c02b87b8-7c98-4135-ae99-34c4a92ba9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to help you understand how to create a Dockerfile for a Python application.\n",
      "\n",
      "A Dockerfile is a text file that contains a series of commands that are used to build a Docker image. The Dockerfile is used to define the base image, install dependencies, copy files, and set environment variables.\n",
      "\n",
      "Here's a basic example of a Dockerfile for a Python application:\n",
      "\n",
      "```\n",
      "# Use an official Python runtime as the base image\n",
      "FROM python:3.9-slim\n",
      "\n",
      "# Set the working directory in the container to /app\n",
      "WORKDIR /app\n",
      "\n",
      "# Copy the requirements file\n",
      "COPY requirements.txt.\n",
      "\n",
      "# Install the dependencies\n",
      "RUN pip install -r requirements.txt\n",
      "\n",
      "# Copy the application code\n",
      "COPY..\n",
      "\n",
      "# Expose the port the application will run on\n",
      "EXPOSE 5000\n",
      "\n",
      "# Run the command to start the application\n",
      "CMD [\"python\", \"app.py\"]\n",
      "```\n",
      "\n",
      "Let's break down what each part of the Dockerfile does:\n",
      "\n",
      "1. `FROM python:3.9-slim`: This line tells Docker to use the official Python 3.9 image as the base image for our application. The `slim` tag indicates that we want a lightweight image.\n",
      "\n",
      "2. `WORKDIR /app`: This line sets the working directory in the container to `/app`. This is where our application code will be copied to.\n",
      "\n",
      "3. `COPY requirements.txt.`: This line copies the `requirements.txt` file from the current directory (on the host machine) to the `/app` directory in the container.\n",
      "\n",
      "4. `RUN pip install -r requirements.txt`: This line installs the dependencies specified in the `requirements.txt` file using pip.\n",
      "\n",
      "5. `COPY..`: This line copies the application code from the current directory (on the host machine) to the `/app` directory in the container.\n",
      "\n",
      "6. `EXPOSE 5000`: This line tells Docker that our application will be listening on port 5000.\n",
      "\n",
      "7. `CMD [\"python\", \"app.py\"]`: This line sets the default command to run when the container is started. In this case, it runs the `app.py` file using the Python interpreter.\n",
      "\n",
      "Here's a step-by-step guide to create a Dockerfile for a Python application:\n",
      "\n",
      "1. Create a new directory for your project and navigate to it in your terminal.\n",
      "\n",
      "2. Create a new file called `Dockerfile` in the project directory.\n",
      "\n",
      "3. Open the `Dockerfile` in a text editor and add the following lines:\n",
      "\n",
      "```\n",
      "FROM python:3.9-slim\n",
      "WORKDIR /app\n",
      "COPY requirements.txt.\n",
      "RUN pip install -r requirements.txt\n",
      "COPY..\n",
      "EXPOSE 5000\n",
      "CMD [\"python\", \"app.py\"]\n",
      "```\n",
      "\n",
      "4. Replace `app.py` with the name of your Python application file.\n",
      "\n",
      "5. Create a `requirements.txt` file in the project directory and add the dependencies required by your application.\n",
      "\n",
      "6. Create a `app.py` file in the project directory and add your Python application code.\n",
      "\n",
      "7. Run the following command to build the Docker image:\n",
      "\n",
      "```\n",
      "docker build -t my-python-app.\n",
      "```\n",
      "\n",
      "8. Run the following command to start a new container from the image and map port 5000 on the host machine to port 5000 in the container:\n",
      "\n",
      "```\n",
      "docker run -p 5000:5000 my-python-app\n",
      "```\n",
      "\n",
      "9. You can now access your application by visiting `http://localhost:5000` in your web browser.\n",
      "\n",
      "I hope this helps! Let me know if you have any questions.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a coding assistant, answer user queries as requested\"},\n",
    "    {\"role\": \"user\", \"content\": \"I'm new to Docker. Can you explain how to create a Dockerfile for a Python application and what each part of the Dockerfile does?\"},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=4096,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ac790bd-6b8b-4f02-8930-06cec710f2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OAuth (Open Authorization) is an authorization framework that allows users to grant third-party applications limited access to their resources on another service provider's website, without sharing their login credentials. Here's a step-by-step guide on how to implement OAuth authentication in a Python web application, along with examples of integrating with Google and Facebook:\n",
      "\n",
      "**Step 1: Register your application with the OAuth provider**\n",
      "\n",
      "* Go to the Google Cloud Console (<https://console.cloud.google.com/>) and create a new project.\n",
      "* Click on \"OAuth consent screen\" and fill in the required information.\n",
      "* Click on \"Credentials\" and create a new OAuth client ID.\n",
      "* Choose \"Web application\" and enter your authorized JavaScript origins.\n",
      "* Note down the Client ID and Client secret.\n",
      "\n",
      "* For Facebook, go to the Facebook for Developers platform (<https://developers.facebook.com/>) and create a new app.\n",
      "* Click on \"Add Product\" and select \"Facebook Login\".\n",
      "* Fill in the required information and click \"Save Changes\".\n",
      "* Note down the App ID and App Secret.\n",
      "\n",
      "**Step 2: Install the required libraries**\n",
      "\n",
      "* Install the `requests` and `requests-oauthlib` libraries using pip:\n",
      "```\n",
      "pip install requests requests-oauthlib\n",
      "```\n",
      "**Step 3: Implement the OAuth flow**\n",
      "\n",
      "* The OAuth flow consists of three main steps: authorization, token exchange, and token validation.\n",
      "\n",
      "**Authorization Step**\n",
      "\n",
      "* Redirect the user to the OAuth provider's authorization URL, which includes the client ID, response type, and redirect URI:\n",
      "```python\n",
      "import requests\n",
      "import requests_oauthlib\n",
      "\n",
      "# Google OAuth\n",
      "auth_url = \"https://accounts.google.com/o/oauth2/v2/auth\"\n",
      "params = {\n",
      "    \"client_id\": \"YOUR_CLIENT_ID\",\n",
      "    \"response_type\": \"code\",\n",
      "    \"redirect_uri\": \"YOUR_REDIRECT_URI\",\n",
      "    \"scope\": \"email profile\"\n",
      "}\n",
      "response = requests.get(auth_url, params=params)\n",
      "\n",
      "# Facebook OAuth\n",
      "auth_url = \"https://www.facebook.com/v3.3/dialog/oauth\"\n",
      "params = {\n",
      "    \"client_id\": \"YOUR_APP_ID\",\n",
      "    \"response_type\": \"code\",\n",
      "    \"redirect_uri\": \"YOUR_REDIRECT_URI\",\n",
      "    \"scope\": \"email\"\n",
      "}\n",
      "response = requests.get(auth_url, params=params)\n",
      "```\n",
      "* The user will be redirected to the OAuth provider's authorization page, where they will be prompted to grant access to your application.\n",
      "\n",
      "**Token Exchange Step**\n",
      "\n",
      "* After the user grants access, the OAuth provider will redirect them back to your application with an authorization code.\n",
      "* Exchange the authorization code for an access token by sending a POST request to the token endpoint:\n",
      "```python\n",
      "# Google OAuth\n",
      "token_url = \"https://oauth2.googleapis.com/token\"\n",
      "params = {\n",
      "    \"code\": \"AUTHORIZATION_CODE\",\n",
      "    \"redirect_uri\": \"YOUR_REDIRECT_URI\",\n",
      "    \"client_id\": \"YOUR_CLIENT_ID\",\n",
      "    \"client_secret\": \"YOUR_CLIENT_SECRET\",\n",
      "    \"grant_type\": \"authorization_code\"\n",
      "}\n",
      "response = requests.post(token_url, data=params)\n",
      "\n",
      "# Facebook OAuth\n",
      "token_url = \"https://graph.facebook.com/v3.3/oauth/access_token\"\n",
      "params = {\n",
      "    \"client_id\": \"YOUR_APP_ID\",\n",
      "    \"client_secret\": \"YOUR_APP_SECRET\",\n",
      "    \"redirect_uri\": \"YOUR_REDIRECT_URI\",\n",
      "    \"code\": \"AUTHORIZATION_CODE\"\n",
      "}\n",
      "response = requests.post(token_url, data=params)\n",
      "```\n",
      "* The response will contain an access token, which can be used to access the user's data.\n",
      "\n",
      "**Token Validation Step**\n",
      "\n",
      "* Validate the access token by sending a GET request to the token information endpoint:\n",
      "```python\n",
      "# Google OAuth\n",
      "token_info_url = \"https://oauth2.googleapis.com/tokeninfo\"\n",
      "params = {\n",
      "    \"access_token\": \"ACCESS_TOKEN\"\n",
      "}\n",
      "response = requests.get(token_info_url, params=params)\n",
      "\n",
      "# Facebook OAuth\n",
      "token_info_url = \"https://graph.facebook.com/v3.3/debug_token\"\n",
      "params = {\n",
      "    \"input_token\": \"ACCESS_TOKEN\"\n",
      "}\n",
      "response = requests.get(token_info_url, params=params)\n",
      "```\n",
      "* The response will contain information about the access token, such as the user's ID and email address.\n",
      "\n",
      "**Example Code**\n",
      "\n",
      "Here's an example of how to implement OAuth authentication in a Python web application using Flask:\n",
      "```python\n",
      "from flask import Flask, redirect, url_for\n",
      "import requests\n",
      "import requests_oauthlib\n",
      "\n",
      "app = Flask(__name__)\n",
      "\n",
      "# Google OAuth\n",
      "client_id = \"YOUR_CLIENT_ID\"\n",
      "client_secret = \"YOUR_CLIENT_SECRET\"\n",
      "redirect_uri = \"YOUR_REDIRECT_URI\"\n",
      "\n",
      "@app.route(\"/\")\n",
      "def index():\n",
      "    return \"Hello, World!\"\n",
      "\n",
      "@app.route(\"/login\")\n",
      "def login():\n",
      "    auth_url = \"https://accounts.google.com/o/oauth2/v2/auth\"\n",
      "    params = {\n",
      "        \"client_id\": client_id,\n",
      "        \"response_type\": \"code\",\n",
      "        \"redirect_uri\": redirect_uri,\n",
      "        \"scope\": \"email profile\"\n",
      "    }\n",
      "    return redirect(auth_url, params=params)\n",
      "\n",
      "@app.route(\"/callback\")\n",
      "def callback():\n",
      "    code = request.args.get(\"code\")\n",
      "    token_url = \"https://oauth2.googleapis.com/token\"\n",
      "    params = {\n",
      "        \"code\": code,\n",
      "        \"redirect_uri\": redirect_uri,\n",
      "        \"client_id\": client_id,\n",
      "        \"client_secret\": client_secret,\n",
      "        \"grant_type\": \"authorization_code\"\n",
      "    }\n",
      "    response = requests.post(token_url, data=params)\n",
      "    access_token = response.json()[\"access_token\"]\n",
      "    # Use the access token to access the user's data\n",
      "    return \"Access token: {}\".format(access_token)\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    app.run(debug=True)\n",
      "```\n",
      "This example demonstrates how to implement OAuth authentication with Google using the `requests` and `requests-oauthlib` libraries. You can modify the code to integrate with Facebook or other OAuth providers.\n",
      "\n",
      "**Security Considerations**\n",
      "\n",
      "* Always store the client secret securely and never expose it to the public.\n",
      "* Use HTTPS to encrypt the communication between your application and the OAuth provider.\n",
      "* Validate the access token and user data to ensure that the user has granted the necessary permissions.\n",
      "* Handle errors and exceptions properly to prevent security vulnerabilities.\n",
      "\n",
      "I hope this helps! Let me know if you have any further questions.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a coding assistant, answer user queries as requested\"},\n",
    "    {\"role\": \"user\", \"content\": \"Explain how to implement OAuth authentication in a Python web application. Provide examples of how to integrate with an external OAuth provider like Google or Facebook.\"},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=4096,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "615ada24-390e-4602-a3ff-c8d8f422eec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a step-by-step guide on how to use PyTorch to build a neural network for recognizing handwritten digits:\n",
      "\n",
      "**Step 1: Install necessary libraries and load the dataset**\n",
      "\n",
      "You'll need to install PyTorch and the necessary libraries. You can install them using pip:\n",
      "```\n",
      "pip install torch torchvision\n",
      "```\n",
      "Load the MNIST dataset, which is a popular dataset for handwritten digit recognition:\n",
      "```python\n",
      "import torch\n",
      "import torchvision\n",
      "import torchvision.transforms as transforms\n",
      "\n",
      "transform = transforms.Compose([transforms.ToTensor()])\n",
      "trainset = torchvision.datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
      "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
      "\n",
      "testset = torchvision.datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
      "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
      "```\n",
      "**Step 2: Preprocess the data**\n",
      "\n",
      "The MNIST dataset consists of 28x28 images, which are too large for our model. We'll resize them to 28x28 and normalize the pixel values to be between 0 and 1:\n",
      "```python\n",
      "import torch.nn.functional as F\n",
      "\n",
      "def preprocess_image(image):\n",
      "    return F.interpolate(image.unsqueeze(0), size=(28, 28), mode='bilinear').squeeze(0)\n",
      "\n",
      "train_images = [preprocess_image(image) for image, _ in trainset]\n",
      "test_images = [preprocess_image(image) for image, _ in testset]\n",
      "```\n",
      "**Step 3: Define the neural network model**\n",
      "\n",
      "We'll define a simple convolutional neural network (CNN) with two convolutional layers and two fully connected layers:\n",
      "```python\n",
      "import torch.nn as nn\n",
      "\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
      "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
      "        self.fc1 = nn.Linear(16*4*4, 120)\n",
      "        self.fc2 = nn.Linear(120, 84)\n",
      "        self.fc3 = nn.Linear(84, 10)\n",
      "\n",
      "    def forward(self, x):\n",
      "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
      "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
      "        x = x.view(-1, 16*4*4)\n",
      "        x = F.relu(self.fc1(x))\n",
      "        x = F.relu(self.fc2(x))\n",
      "        x = self.fc3(x)\n",
      "        return x\n",
      "```\n",
      "**Step 4: Train the model**\n",
      "\n",
      "We'll define a loss function (cross-entropy) and an optimizer (Stochastic Gradient Descent):\n",
      "```python\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
      "```\n",
      "We'll train the model using the training data:\n",
      "```python\n",
      "for epoch in range(2):  # loop over the dataset multiple times\n",
      "    running_loss = 0.0\n",
      "    for i, data in enumerate(trainloader, 0):\n",
      "        inputs, labels = data\n",
      "        optimizer.zero_grad()\n",
      "        outputs = net(inputs)\n",
      "        loss = criterion(outputs, labels)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        running_loss += loss.item()\n",
      "    print('Epoch %d, Loss: %.3f' % (epoch+1, running_loss/(i+1)))\n",
      "```\n",
      "**Step 5: Evaluate the model**\n",
      "\n",
      "We'll evaluate the model using the test data:\n",
      "```python\n",
      "correct = 0\n",
      "total = 0\n",
      "with torch.no_grad():\n",
      "    for data in testloader:\n",
      "        images, labels = data\n",
      "        outputs = net(images)\n",
      "        _, predicted = torch.max(outputs.data, 1)\n",
      "        total += labels.size(0)\n",
      "        correct += (predicted == labels).sum().item()\n",
      "\n",
      "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
      "```\n",
      "That's it! You've built a neural network using PyTorch to recognize handwritten digits. You can adjust the hyperparameters, architecture, and training procedure to improve the model's performance.\n",
      "\n",
      "Here's the complete code:\n",
      "```python\n",
      "import torch\n",
      "import torchvision\n",
      "import torchvision.transforms as transforms\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "transform = transforms.Compose([transforms.ToTensor()])\n",
      "trainset = torchvision.datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
      "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
      "\n",
      "testset = torchvision.datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
      "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
      "\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
      "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
      "        self.fc1 = nn.Linear(16*4*4, 120)\n",
      "        self.fc2 = nn.Linear(120, 84)\n",
      "        self.fc3 = nn.Linear(84, 10)\n",
      "\n",
      "    def forward(self, x):\n",
      "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
      "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
      "        x = x.view(-1, 16*4*4)\n",
      "        x = F.relu(self.fc1(x))\n",
      "        x = F.relu(self.fc2(x))\n",
      "        x = self.fc3(x)\n",
      "        return x\n",
      "\n",
      "net = Net()\n",
      "\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
      "\n",
      "for epoch in range(2):  # loop over the dataset multiple times\n",
      "    running_loss = 0.0\n",
      "    for i, data in enumerate(trainloader, 0):\n",
      "        inputs, labels = data\n",
      "        optimizer.zero_grad()\n",
      "        outputs = net(inputs)\n",
      "        loss = criterion(outputs, labels)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        running_loss += loss.item()\n",
      "    print('Epoch %d, Loss: %.3f' % (epoch+1, running_loss/(i+1)))\n",
      "\n",
      "correct = 0\n",
      "total = 0\n",
      "with torch.no_grad():\n",
      "    for data in testloader:\n",
      "        images, labels = data\n",
      "        outputs = net(images)\n",
      "        _, predicted = torch.max(outputs.data, 1)\n",
      "        total += labels.size(0)\n",
      "        correct += (predicted == labels).sum().item()\n",
      "\n",
      "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
      "```\n",
      "I hope this helps! Let me know if you have any questions.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a coding assistant, answer user queries as requested\"},\n",
    "    {\"role\": \"user\", \"content\": \"How can I use pytorch to build a neural network for recognizing handwritten digits? Provide a step-by-step guide including data preprocessing and model training\"},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=4096,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "281d8a0e-364e-4bad-b3e4-448b4f67d11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a step-by-step guide on how to set up a GraphQL server in Node.js:\n",
      "\n",
      "**Step 1: Install the necessary dependencies**\n",
      "\n",
      "You'll need to install the following dependencies:\n",
      "\n",
      "* `graphql`: The official GraphQL library for Node.js\n",
      "* `express`: A popular web framework for Node.js\n",
      "\n",
      "Run the following command in your terminal:\n",
      "```\n",
      "npm install graphql express\n",
      "```\n",
      "**Step 2: Create a new Node.js project**\n",
      "\n",
      "Create a new directory for your project and navigate into it:\n",
      "```\n",
      "mkdir graphql-server\n",
      "cd graphql-server\n",
      "```\n",
      "Create a new file called `server.js` and add the following code:\n",
      "```\n",
      "const express = require('express');\n",
      "const { graphqlHTTP } = require('express-graphql');\n",
      "const { buildSchema } = require('graphql');\n",
      "\n",
      "const app = express();\n",
      "\n",
      "// Define the GraphQL schema\n",
      "const schema = buildSchema(`\n",
      "  type Query {\n",
      "    hello: String\n",
      "  }\n",
      "\n",
      "  type Mutation {\n",
      "    sendMessage(name: String!, message: String!): String\n",
      "  }\n",
      "`);\n",
      "\n",
      "// Create a resolver for the Query type\n",
      "const resolvers = {\n",
      "  Query: {\n",
      "    hello: () => 'Hello, world!'\n",
      "  },\n",
      "  Mutation: {\n",
      "    sendMessage: (parent, { name, message }) => `Hello, ${name}! You sent the message: ${message}`\n",
      "  }\n",
      "};\n",
      "\n",
      "// Create a GraphQL server\n",
      "app.use('/graphql', graphqlHTTP({\n",
      "  schema: schema,\n",
      "  graphiql: true\n",
      "}));\n",
      "\n",
      "// Start the server\n",
      "const port = 4000;\n",
      "app.listen(port, () => {\n",
      "  console.log(`Server started on port ${port}`);\n",
      "});\n",
      "```\n",
      "This code sets up an Express server that serves a GraphQL schema with a single query and mutation. The `buildSchema` function is used to define the schema, and the `resolvers` object is used to define the resolvers for the schema.\n",
      "\n",
      "**Step 3: Define the schema**\n",
      "\n",
      "The schema defines the types and fields that are available in your GraphQL API. In this example, we have a `Query` type with a single field `hello`, and a `Mutation` type with a single field `sendMessage`.\n",
      "\n",
      "**Step 4: Define the resolvers**\n",
      "\n",
      "Resolvers are functions that are called when a client queries or mutates data. In this example, we have two resolvers:\n",
      "\n",
      "* `hello`: Returns the string \"Hello, world!\"\n",
      "* `sendMessage`: Takes two arguments `name` and `message`, and returns a string that includes the name and message.\n",
      "\n",
      "**Step 5: Create a GraphQL server**\n",
      "\n",
      "The `graphqlHTTP` middleware is used to create a GraphQL server. We pass in the schema and the resolvers as options.\n",
      "\n",
      "**Step 6: Start the server**\n",
      "\n",
      "Finally, we start the server by calling `app.listen` and specifying the port number.\n",
      "\n",
      "**Handling queries and mutations**\n",
      "\n",
      "To handle queries and mutations, you can use a GraphQL client library such as `apollo-client` or `graphql-tag`. Here's an example of how you can use `apollo-client` to query and mutate data:\n",
      "\n",
      "```\n",
      "import { ApolloClient, InMemoryCache } from '@apollo/client';\n",
      "import { gql } from '@apollo/client';\n",
      "\n",
      "const client = new ApolloClient({\n",
      "  uri: 'http://localhost:4000/graphql',\n",
      "  cache: new InMemoryCache()\n",
      "});\n",
      "\n",
      "// Query data\n",
      "client.query({\n",
      "  query: gql`\n",
      "    query {\n",
      "      hello\n",
      "    }\n",
      "  `\n",
      "}).then(result => console.log(result.data));\n",
      "\n",
      "// Mutate data\n",
      "client.mutate({\n",
      "  mutation: gql`\n",
      "    mutation {\n",
      "      sendMessage(name: \"John\", message: \"Hello, world!\")\n",
      "    }\n",
      "  `\n",
      "}).then(result => console.log(result.data));\n",
      "```\n",
      "This code creates an Apollo client instance and uses it to query and mutate data. The `query` method is used to query data, and the `mutate` method is used to mutate data.\n",
      "\n",
      "That's it! You now have a basic GraphQL server set up in Node.js. You can use a GraphQL client library to query and mutate data, and you can define more complex schema and resolvers as needed.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a coding assistant, answer user queries as requested\"},\n",
    "    {\"role\": \"user\", \"content\": \"Explain how to set up a GraphQL server in Node.js. Provide a step-by-step guide including handling queries and mutations.\"},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=4096,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "853d1cf6-ebad-4f39-a300-0f54ff3c7c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrating a payment gateway like Stripe into a web application involves several steps, including setting up an account, obtaining API keys, and implementing payment processing. Here's a step-by-step guide on how to integrate Stripe into a web application:\n",
      "\n",
      "**Step 1: Create a Stripe Account**\n",
      "\n",
      "1. Go to Stripe's website ([stripe.com](http://stripe.com)) and sign up for an account.\n",
      "2. Fill out the registration form with your business information and verify your email address.\n",
      "3. Set up your Stripe account by providing additional information, such as your business name, address, and tax information.\n",
      "\n",
      "**Step 2: Obtain API Keys**\n",
      "\n",
      "1. Log in to your Stripe dashboard and navigate to the \"Developers\" section.\n",
      "2. Click on \"API keys\" and generate a new set of API keys (live and test).\n",
      "3. Note down the API keys, as you'll need them to make API requests to Stripe.\n",
      "\n",
      "**Step 3: Set up Stripe in Your Web Application**\n",
      "\n",
      "1. Install the Stripe JavaScript library by including the following script tag in your HTML file:\n",
      "```html\n",
      "<script src=\"https://js.stripe.com/v3/\"></script>\n",
      "```\n",
      "2. Initialize the Stripe library by calling the `Stripe` constructor and passing in your API keys:\n",
      "```javascript\n",
      "const stripe = Stripe('pk_test_YOUR_LIVE_API_KEY', {\n",
      "  apiVersion: '2022-08-01',\n",
      "});\n",
      "```\n",
      "**Step 4: Handle Payments**\n",
      "\n",
      "1. Create a payment form on your website that accepts credit card information. You can use Stripe's Elements library to create a customizable payment form:\n",
      "```javascript\n",
      "const paymentForm = document.getElementById('payment-form');\n",
      "paymentForm.addEventListener('submit', (event) => {\n",
      "  event.preventDefault();\n",
      "  const cardNumber = document.getElementById('card-number').value;\n",
      "  const expMonth = document.getElementById('exp-month').value;\n",
      "  const expYear = document.getElementById('exp-year').value;\n",
      "  const cvc = document.getElementById('cvc').value;\n",
      "\n",
      "  stripe.createPaymentMethod('card', {\n",
      "    number: cardNumber,\n",
      "    exp_month: expMonth,\n",
      "    exp_year: expYear,\n",
      "    cvc: cvc,\n",
      "  })\n",
      "   .then((result) => {\n",
      "      // Create a payment intent\n",
      "      stripe.createPaymentIntent({\n",
      "        amount: 1000, // Amount in cents\n",
      "        currency: 'usd',\n",
      "      })\n",
      "       .then((result) => {\n",
      "          // Confirm the payment\n",
      "          stripe.confirmPaymentIntent(result.paymentIntent.client_secret, {\n",
      "            payment_method: result.paymentMethod.id,\n",
      "          })\n",
      "           .then((result) => {\n",
      "              if (result.paymentIntent.status ==='succeeded') {\n",
      "                // Payment successful\n",
      "                console.log('Payment successful!');\n",
      "              } else {\n",
      "                // Payment failed\n",
      "                console.log('Payment failed!');\n",
      "              }\n",
      "            });\n",
      "        });\n",
      "    });\n",
      "});\n",
      "```\n",
      "**Step 5: Secure Transactions**\n",
      "\n",
      "1. Use Stripe's server-side verification to validate payment information and prevent fraud:\n",
      "```javascript\n",
      "const express = require('express');\n",
      "const app = express();\n",
      "const stripe = require('stripe')('YOUR_LIVE_API_KEY');\n",
      "\n",
      "app.post('/create-payment-intent', (req, res) => {\n",
      "  const { amount, currency } = req.body;\n",
      "  stripe.createPaymentIntent({\n",
      "    amount: amount * 100, // Amount in cents\n",
      "    currency: currency,\n",
      "  })\n",
      "   .then((result) => {\n",
      "      res.json(result);\n",
      "    });\n",
      "});\n",
      "\n",
      "app.post('/confirm-payment', (req, res) => {\n",
      "  const { paymentIntentClientSecret, paymentMethodId } = req.body;\n",
      "  stripe.confirmPaymentIntent(paymentIntentClientSecret, {\n",
      "    payment_method: paymentMethodId,\n",
      "  })\n",
      "   .then((result) => {\n",
      "      if (result.paymentIntent.status ==='succeeded') {\n",
      "        // Payment successful\n",
      "        res.json({ message: 'Payment successful!' });\n",
      "      } else {\n",
      "        // Payment failed\n",
      "        res.json({ message: 'Payment failed!' });\n",
      "      }\n",
      "    });\n",
      "});\n",
      "```\n",
      "**Step 6: Handle Webhooks**\n",
      "\n",
      "1. Set up webhooks to receive notifications from Stripe when a payment is successful or failed:\n",
      "```javascript\n",
      "const express = require('express');\n",
      "const app = express();\n",
      "const stripe = require('stripe')('YOUR_LIVE_API_KEY');\n",
      "\n",
      "app.post('/webhook', (req, res) => {\n",
      "  const event = req.body;\n",
      "  if (event.type === 'payment_intent.succeeded') {\n",
      "    // Payment successful\n",
      "    console.log('Payment successful!');\n",
      "  } else if (event.type === 'payment_intent.failed') {\n",
      "    // Payment failed\n",
      "    console.log('Payment failed!');\n",
      "  }\n",
      "  res.json({ received: true });\n",
      "});\n",
      "```\n",
      "By following these steps, you can integrate Stripe into your web application and securely handle payments. Remember to keep your API keys secure and follow Stripe's best practices for security and compliance.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a coding assistant, answer user queries as requested\"},\n",
    "    {\"role\": \"user\", \"content\": \"Describe the steps to integrate a payment gateway like Stripe into a web application. Include examples of handling payments and securing transactions.\"},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=4096,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b52dba9-4a63-4dfd-a341-3e9ce53ee14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a step-by-step guide on how to create a containerized development environment for a React application using Docker:\n",
      "\n",
      "**Step 1: Create a new React project**\n",
      "\n",
      "First, create a new React project using the following command:\n",
      "```\n",
      "npx create-react-app my-react-app\n",
      "```\n",
      "This will create a new React project in a directory called `my-react-app`.\n",
      "\n",
      "**Step 2: Create a Dockerfile**\n",
      "\n",
      "Create a new file called `Dockerfile` in the root directory of your React project. This file will contain the instructions for building your Docker image.\n",
      "\n",
      "Here's an example `Dockerfile`:\n",
      "```\n",
      "# Use an official Node.js 14 image as a base\n",
      "FROM node:14\n",
      "\n",
      "# Set the working directory in the container to /app\n",
      "WORKDIR /app\n",
      "\n",
      "# Copy the current directory contents into the container at /app\n",
      "COPY. /app\n",
      "\n",
      "# Install any necessary dependencies\n",
      "RUN npm install\n",
      "\n",
      "# Make port 3000 available to the world outside this container\n",
      "EXPOSE 3000\n",
      "\n",
      "# Run npm start when the container launches\n",
      "CMD [\"npm\", \"start\"]\n",
      "```\n",
      "Let's break down what each line does:\n",
      "\n",
      "* `FROM node:14`: This line tells Docker to use the official Node.js 14 image as a base for our image.\n",
      "* `WORKDIR /app`: This line sets the working directory in the container to `/app`.\n",
      "* `COPY. /app`: This line copies the current directory contents into the container at `/app`.\n",
      "* `RUN npm install`: This line installs any necessary dependencies specified in the `package.json` file.\n",
      "* `EXPOSE 3000`: This line makes port 3000 available to the world outside this container.\n",
      "* `CMD [\"npm\", \"start\"]`: This line runs the `npm start` command when the container launches.\n",
      "\n",
      "**Step 3: Build the Docker image**\n",
      "\n",
      "To build the Docker image, run the following command:\n",
      "```\n",
      "docker build -t my-react-app.\n",
      "```\n",
      "This command tells Docker to build an image with the tag `my-react-app` using the instructions in the `Dockerfile`.\n",
      "\n",
      "**Step 4: Run the Docker container**\n",
      "\n",
      "To run the Docker container, run the following command:\n",
      "```\n",
      "docker run -p 3000:3000 my-react-app\n",
      "```\n",
      "This command tells Docker to run a container from the `my-react-app` image and map port 3000 on the host machine to port 3000 in the container.\n",
      "\n",
      "**Step 5: Verify the container**\n",
      "\n",
      "Open a web browser and navigate to `http://localhost:3000`. You should see your React application running in the container.\n",
      "\n",
      "**Step 6: Make changes and rebuild the image**\n",
      "\n",
      "Make some changes to your React application, such as updating a component or adding a new feature. Then, rebuild the Docker image by running the following command:\n",
      "```\n",
      "docker build -t my-react-app.\n",
      "```\n",
      "This will rebuild the image with the latest changes.\n",
      "\n",
      "**Step 7: Run the updated container**\n",
      "\n",
      "Run the updated container by running the following command:\n",
      "```\n",
      "docker run -p 3000:3000 my-react-app\n",
      "```\n",
      "This will run the updated container with the latest changes.\n",
      "\n",
      "That's it! You now have a containerized development environment for your React application using Docker.\n",
      "\n",
      "Note: You can also use a `.dockerignore` file to ignore certain files and directories when building the image. For example, you can ignore the `node_modules` directory by adding the following line to your `.dockerignore` file:\n",
      "```\n",
      "node_modules/\n",
      "```\n",
      "This will prevent Docker from copying the `node_modules` directory into the container, which can save disk space and improve build times.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a coding assistant, answer user queries as requested\"},\n",
    "    {\"role\": \"user\", \"content\": \"How can I use Docker to create a containerized development environment for a React application? Provide detailed steps including Dockerfile creation.\"},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=4096,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2162ed4f-3973-440c-8eb0-aafac1df2a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache Kafka is a popular open-source distributed streaming platform designed for building real-time data processing pipelines. Here's a step-by-step guide on how to use Apache Kafka for real-time data processing in a Java application:\n",
      "\n",
      "**Architecture Overview**\n",
      "\n",
      "The Apache Kafka architecture consists of the following components:\n",
      "\n",
      "1. **Producers**: These are the applications that send data to Kafka. In your case, you'll be using a Java application as a producer.\n",
      "2. **Brokers**: These are the nodes that run the Kafka server and manage the data. You can have multiple brokers in a Kafka cluster.\n",
      "3. **Topics**: These are the logical channels where data is published and consumed. Each topic is divided into partitions, which are stored on different brokers.\n",
      "4. **Consumers**: These are the applications that read data from Kafka. You'll also be using a Java application as a consumer.\n",
      "\n",
      "**Setting up Kafka**\n",
      "\n",
      "To set up Kafka, follow these steps:\n",
      "\n",
      "1. Download and install Kafka from the official Apache Kafka website.\n",
      "2. Start the Kafka server by running the following command in the Kafka directory:\n",
      "```\n",
      "bin/kafka-server-start.sh config/server.properties\n",
      "```\n",
      "3. Create a new topic by running the following command:\n",
      "```\n",
      "bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 my_topic\n",
      "```\n",
      "Replace `my_topic` with the name of your topic.\n",
      "\n",
      "**Producer Setup**\n",
      "\n",
      "To set up a producer in your Java application, follow these steps:\n",
      "\n",
      "1. Add the Kafka dependencies to your project. For Maven, add the following dependency to your `pom.xml` file:\n",
      "```xml\n",
      "<dependency>\n",
      "    <groupId>org.apache.kafka</groupId>\n",
      "    <artifactId>kafka-clients</artifactId>\n",
      "    <version>2.8.0</version>\n",
      "</dependency>\n",
      "```\n",
      "For Gradle, add the following dependency to your `build.gradle` file:\n",
      "```groovy\n",
      "dependencies {\n",
      "    implementation 'org.apache.kafka:kafka-clients:2.8.0'\n",
      "}\n",
      "```\n",
      "2. Create a producer configuration object:\n",
      "```java\n",
      "Properties props = new Properties();\n",
      "props.put(\"bootstrap.servers\", \"localhost:9092\");\n",
      "props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n",
      "props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n",
      "Producer<String, String> producer = new KafkaProducer<>(props);\n",
      "```\n",
      "Replace `localhost:9092` with the hostname and port of your Kafka broker.\n",
      "\n",
      "3. Create a producer record and send it to Kafka:\n",
      "```java\n",
      "ProducerRecord<String, String> record = new ProducerRecord<>(\"my_topic\", \"key\", \"value\");\n",
      "producer.send(record);\n",
      "```\n",
      "Replace `my_topic` with the name of your topic.\n",
      "\n",
      "**Consumer Setup**\n",
      "\n",
      "To set up a consumer in your Java application, follow these steps:\n",
      "\n",
      "1. Add the Kafka dependencies to your project. For Maven, add the following dependency to your `pom.xml` file:\n",
      "```xml\n",
      "<dependency>\n",
      "    <groupId>org.apache.kafka</groupId>\n",
      "    <artifactId>kafka-clients</artifactId>\n",
      "    <version>2.8.0</version>\n",
      "</dependency>\n",
      "```\n",
      "For Gradle, add the following dependency to your `build.gradle` file:\n",
      "```groovy\n",
      "dependencies {\n",
      "    implementation 'org.apache.kafka:kafka-clients:2.8.0'\n",
      "}\n",
      "```\n",
      "2. Create a consumer configuration object:\n",
      "```java\n",
      "Properties props = new Properties();\n",
      "props.put(\"bootstrap.servers\", \"localhost:9092\");\n",
      "props.put(\"group.id\", \"my_group\");\n",
      "props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\n",
      "props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\n",
      "Consumer<String, String> consumer = new KafkaConsumer<>(props);\n",
      "```\n",
      "Replace `localhost:9092` with the hostname and port of your Kafka broker, and `my_group` with the name of your consumer group.\n",
      "\n",
      "3. Subscribe to the topic:\n",
      "```java\n",
      "consumer.subscribe(Arrays.asList(\"my_topic\"));\n",
      "```\n",
      "Replace `my_topic` with the name of your topic.\n",
      "\n",
      "4. Consume messages from Kafka:\n",
      "```java\n",
      "while (true) {\n",
      "    ConsumerRecords<String, String> records = consumer.poll(100);\n",
      "    for (ConsumerRecord<String, String> record : records) {\n",
      "        System.out.println(record.value());\n",
      "    }\n",
      "    consumer.commitSync();\n",
      "}\n",
      "```\n",
      "This code will consume messages from Kafka and print them to the console.\n",
      "\n",
      "That's it! You've set up a Kafka producer and consumer in your Java application. You can now send data to Kafka using the producer and consume data from Kafka using the consumer.\n",
      "\n",
      "Remember to replace the placeholders (`localhost:9092`, `my_topic`, `my_group`) with the actual values for your Kafka setup.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a coding assistant, answer user queries as requested\"},\n",
    "    {\"role\": \"user\", \"content\": \"Teach me how to use Apache Kafka for real-time data processing in a Java application. Explain the architecture and how to set up producers and consumers.\"},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=4096,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9414a6c-85ba-4f61-b5e4-5a1a357179a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
